# Теория отказоустойчивых распределённых систем (Theory of fault-tolerant distributed systems)

Конспект лекций и семинаров курса Романа Липовского 2020 и 2021 годов прочтения\
[Лекции 2021](https://www.youtube.com/playlist?list=PL4_hYwCyhAvaYKF6HkyCximCvlExxxnrC), 
[Семинары 2021](https://www.youtube.com/playlist?list=PL4_hYwCyhAvZd6B5fN3yAB0zOCjhgpfgg)\
[Лекции 2020](https://www.youtube.com/playlist?list=PL4_hYwCyhAvZaJ3CJlGo9FxOTA2bS1YyN), 
[Семинары 2020](https://www.youtube.com/playlist?list=PL4_hYwCyhAvZTjajkPpwgR29jyx81lMCl)

## Содержание

[Lecture 1](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/README.md#lecture-1-модель-распределённой-системы)\
[Seminar 1](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/README.md#seminar-1-среда-исполнения-распределённой-системы)\
[Lecture 2](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/README.md#lecture-2-линеаризуемость-репликация-регистра-алгоритм-abd)\
[Seminar 2](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/README.md#seminar-2-реализация-регистра-в-коде)

## Lecture 1. Модель распределённой системы

#### Типы распределённых систем

Все современные сетевые сервисы используют распределённые системы различных типов
- **KV Store** - огромная распределённая хэш-таблица с типовыми операциями $Set \left( key, value \right)$ и $Get \left( key \right)$, со случайным доступом поверх последовательных дисков и упорядоченностью элементов (like `std::map`). Весь диапазон ключей шардируется некоторым способом, не обязательно хэш-функцией, и в пределах шардов ключи упорядочиваются. Пример: `Cassandra`, `BigTable`
- **File System** - распределённая система хранения файлов огромных размеров или количеств, не умещающихся на одной машине, с последовательным доступом к данным. Отличается от KV Store паттерном доступа. Пример: `GoogleFS`, `Colossus`, `HDFS`
- **Coordination Service** - распределённая система для построения других распределённых систем. Предоставляет примитивы синхронизации и согласованности: выбор лидера, lease и т.д. Выполняет аналогичную роль что и атомик concurrency. Пример: `ZooKeeper`, `Chubby`
- **Message Queue** - распределённый асинхронный транспорт данных для многих одновременных продюсеров и консьюмеров. Пример: `Apache Kafka`
- **Database** - таблицы/колонки, индексы, транзакции, только распределённо. Самый сложный тип распределённых систем. Пример: `YDB`, `Google Spanner`, `CockroachDB`

В первую очередь это разные модели данных, и лишь во вторую имеют различия в построении. Также все эти системы имеют нераспределённые варианты

#### Причины использовать распределённые системы

- **масштабируемость (Scalability)** - возможность свободно добавлять новые вычислительные ресурсы и/или дисковые ёмкости, или же расти *горизонтально*, когда стало слишком много данных/операций для текущего количества машин, адаптируясь к нагрузке и используя при этом стандартное оборудование (свобода от Vendor Lock)
- **отказоустойчивость (Durability + Reliability + Fault-tolerance + Availability)** - машина/диск может сбоить или даже отказать, поэтому в большом кластере всегда есть машины на обслуживании. Необходимо переживать сбои узлов, проблемы сети, электросети и человеческие ошибки, автоматически (без помощи человека) адаптироваться и скрывать это от пользователя
  - **Durability (Надёжность хранения)** - успешно завершённые операции не будут потеряны даже при сбое системы. Надёжная запись на диск
  - **Reliability (Надёжность работы)** - система выполняет свои функции корректно и стабильно в течение длительного времени. Думаем как предотвратить сбой узла (обслуживание оборудования, логи и мониторинги, тестирование, профилирование, стабилные версии библиотек и ОС и т.д.)
  - **Fault-tolerance (Устойчивость к сбоям)** - корректность работы системы не нарушается при отказах компонентов (узлов, сети, дисков и т.п.). Когда сбой произойдёт, думаем как не пострадать
  - **Availability (Доступность)** - даже если часть компонентов недоступна, система продолжает отвечать на запросы в разумное время, возможно с ограничениями. $4/5$ девяток ($99.99\\%$ или $99.999\\%$)- сколько времени (процент) в год сервер должен быть доступен
- **безопасность (Safity)** - нельзя доверять машине/группе машин, поскольку они могут оказаться злоумышленниками и обманывать остальные машины. Особенно важно в блокчейне

Эти причины независимы. К примеру, отказоустойчивость может быть необходима там, где данные помещаются на одну машину (`ZooKeeper`). Аналогично с безопасностью (`Bitcoin`)

- **согласованность (Consistency)** - ещё одно свойство распределённых систем, гарантировать в той или иной степени, что геораспределённые клиенты будут способны конкурентно взаимодейтсовать с системой и видеть непротиворечивые данные

#### Описание модели

Для построения эффективных и полезных распределённых отказоустойчивых алгоритмов, определим модель, отражающую реальный мир без излишних подробностей. Доказав корректность алгоритмов в этой модели, можно будет утверждать, что они верны и в реальном мире

В этой модели система состоит из
- узлов
- сети (проводов и сообщений)
- клиентов

**Узел (node, process в старых статьях/книгах)** - это автономная единица вычислений и/или хранения, участвующая в совместной работе системы. Это машина, процесс или программная единица, например актор (таблетка в `YDB`). Это сетевой сервис

Узлы взаимодействуют посредством отправки односторонних сообщений (message) без ожидания ответов (reply), используя для этого сеть. **Сеть** есть совокупность проводов. Для простоты, между каждой парой узлов есть прямой и надёжный провод (link, TCP), по которому движутся сообщения, и узлы видят только его. Это модель **Message Passing**

Цель описываемой модели предоставить *гарантии*. Допустим, асинхронно отправили сообщение $m$ узлу $p$ - $Send \left( m, p \right)$. Оно не может дойти моментально, но и верхняя граница неизвестна, только то, что eventually на узле $p$ сработает обработчик сообщения $m$. В реальности вместо ответов применяется механизм Retry-ев, сети более сложные чем прямой провод, а скорость передачи ограничена физически (скорость света + среда/материал) и географически (удалённые узлы, локальность), что вносит задержки, и распределённые системы должны это учитывать. Здесь появляется понятие *стоимости*

Также есть **клиенты**, которые взаимодействуют с узлами по модели **Client-Server** - посылают запросы и ждут ответы. Есть несколько способов взаимодействия
- http api
- RPC - Remote Procedure Call
- client library - плюсовые обёртки над другими API + полезная функциональность, например `Asio`

Клиенты (почти) не знают об узлах. Они отправляют запросы на единый сетевой адрес, которые проксируются в конкретные узлы. Альтернативно балансировка может выполняться в клиентской библиотеке

Клиент выполняет запрос $Set \left( k, X \right)$ и ждёт подтверждение, система отказоустойчиво сохраняет $X$ и посылает это подтверждение. Если затем клиент сообщит об этом другому по внешнему каналу связи, второй ожидает по $Get \left( k \right)$ увидеть $X$, т.е. *наличие причинности*. Клиенты не отправляют сообщения в систему (явно), не видят сотни узлов, не наблюдают распределённость и не думают о ней. Для них система выглядит как бесконечно ёмкий, бесконечно мощный, бесконечно устойчивый компьютер, и в коде это конкурентный объект, поэтому внутри системы удобно использовать модель Message Passing, а снаружи модель **Shared Memory** (Consistency models). При наличии причинности система должна учитывать возможность внешней коммуникации при обеспечинии согласованности. Также возможны распределённые системы, которые заставляют пользователей передавать друг другу служебную информацию для обеспечения причинности по side-channel (за пределами системы). Пример: `Cassandra`, `Dynamo`

В реальности для реализации пересылки узлами друг другу сообщений могут использоваться более высокоуровневые абстракции, например RPC, которые ближе к клиент-сервер модели

#### Гарантии факта доставки сообщения

- **Fair-loss link** - модель честного канала: если узел $A$ будет бесконечно отправлять сообщение узлу $B$, то второй будет бесконечно его получать. Нет момента, когда сообщение навечно перестало доходить. Однако, нет порядка сообщений, нет гарантии доставки, возможны дубликаты. С такой абстракцией неудобно работать
- **Reliable link** - модель надёжного канала: каждое однократно отправленное сообщение будет доставлено, но могут быть дубликаты, и нет порядка
- **Perfect link** - модель идеального канала: каждое однократно отправленное сообщение будет доставлено и ровно один раз, но нет порядка. Пример: TCP - отслеживание дублей, повторная отправка до подтверждения, упорядочение на стороне доставки. Используется в литературе

Эти модели не рассматривают реальность (считают, что узлы/сеть не отказывают), но требуют, чтобы в какие-то периоды времени сеть становилась "идеальной" (доставляла сообщения). Также эти модели не допускают сообщений из воздуха

- **FIFO link** - модель канала, гарантирующая порядок. Ортогональна предыдущим

Будем работать в немного изменённой Reliable модели, где сообщение либо доставится, либо соединение сообщит о разрыве

#### Гарантии времени доставки сообщения

- **Synchronous model (Cинхронная модель)** - время доставки сообщений ограничено сверху $delay \left( m \right) \le \delta$. Непрактична, поскольку в реальности система ненадёжна (разрывы, баги в коммутаторах, высокий трафик, обслуживание, человеческие ошибки и т.д.)
- **Asynchronous model (Асинхронная модель)** - ограничения на время доставки сообщений нет. В этой модели доказывается корректность алгоритмов, т.е. что система обладает свойством **Safity** - не уходит в некорректные состояния (не делает ничего плохого). Но такие алгоритмы/системы бесполезны
- **Partially Synchronous model (Частично синхронная модель)** - модель неопределённо долго асинхронная, но в некоторый неизвестный момент времени $t^\*$ гарантированно станет произвольно коротко синхронной (например, сеть перестала сбоить). Алгоритм должен быть устойчив к худшему сценарию - ждать, когда момент $t^\*$ настанет, и совершить прогресс. В этой модели доказывается, что система делает что-то хорошее, т.е. обладает свойством **Liveness** - eventually совершает прогресс (делает что-то хорошее). Говоря иначе, частично синхронная модель означает, что сеть работает непредсказуемо и не даёт никаких гарантий о времени доставки, но периодически такие гарантии появляются

В зависимости от ситуации будем пользоваться асинхронной или частично синхронной моделью

#### Моделирование сети

- **Partition** - разделение системы на два связных, полностью изолированных друг от друга кластера в результате нарушений сети (отказ link-ов). Также разделяются и пользователи (по модулю проксирования запросов на узлы кластеров)
- **Split Brain** - ситуация, когда при partition кластеры думают, что они вся система, и продолжают работать независимо. Её нельзя допускать, поскольку узлами она ненаблюдаема до и невосстановима после починки сети - консистентность системы нарушится, и клиенты пронаблюдают наличие узлов. Вариант решения: одна из частей должна остановиться до починки (CAP теорема), или обе части дожны перестать работать на запись (?кажется здесь возможна проблема отсутствия последних записей, которые состоялись, но не успели попасть в меньший кластер)

Модель уже учитывает partition - случай бесконечно медленных link-ов на некотором срезе

#### Моделирование узлов

Для целей модели узел есть однопоточный автомат, который получает из сети сообщения и вызывает для них обработчики, меняет своё состояние и, возможно, отвечает сообщениями в сеть/систему. Многопоточность в реализации не влияет на свойства системы, но увеличивает производительность и удобство построения. Для доказательства теорем/алгоритмов можно думать, что все действия узла атомарны, что не повлияет на корректность реальных (неатомарных) систем

Скорость работы узлов произвольная (например может уменьшиться из-за начала сборки мусора/удаления большой структуры объектов). Узел может выйти из строя (Crash, "взорваться", отказ диска). Узел может перезагрузиться (Restart), что требует добавить персистентное состояние (диск). Также возможны Византийские отказы (Byzantine), когда узел ведёт себя непредсказуемым образом, например является злоумышленником и отвечает всем по разному. Последнее сильно усложняет алгоритмы (помимо количества отказов нужно закладывать процент возможных злоумышленников), но и учитывается лишь в безопасных системах (например, криптовалюты)

В зависимости от алгоритма/архитектуры узлы могут быть как равноправными, так и иметь разные роли и даже сменять их (например, лидер)

#### Время

**Время (time)** абсолютно для всех узлов, и каждое событие в системе имеет координату на общей оси времени. Время не влияет на Safity, но должно уважать его при учёте в Liveness. Однако узлы не имеют доступа ко времени, только к **часам (clock)**, которые отображают абсолютное время в **timestamp** $c \left( t \right) \to ts$. В идеале это тождество, но в действительности это оценка $Now \left( \right) \to ts$ от физического процесса в часовом механизме, например кварцевом (quartz, в ПК) или атомном (atomic, точные и дорогие, на специальных машинах)

Принципиально все использования часов сводятся к двум действиям
- $t_1 \lt t_2$ - сравнение timestamp-ов для упорядочивания событий (согласование порядка действий с внешней причинностью)
- $t_2 - t_1$ - вычисление интервала времени для установки timeout-а или организации failure-detection (время ожидания подтверждения доставки сообщения до узла, время отчёта лидера об его активности - heartbeat-ы)

#### Погрешности часов

Часы строят из объектов реального мира, поэтому они имеют погрешности, что необходимо учитывать в алгоритмах
- **Skew** - рассинхронизация часов на разных узлах. Проблема для упорядочивания, когда порядок по часам не соответствует порядку во времени. Пример: клиент $A$ выполнил $Set \left( key, X \right)$ на узле со временем $12:00$, после чего сообщил об этом клиенту $B$, который выполнил $Set \left( key, Y \right)$ на узле со временем $11:59$, но в системе остался $X$ - записи переупорядочились
- **Drift (дрейф, скитание)** - явление нестабильности скорости измерения времени часами, когда часы начинают спешить или отставать. Проблема для точных интервалов. **ppm (parts per million, миллионные доли)** - на сколько микросекунд часы могут отклониться за одну секунду. У кварцевых часов ppm равен $20$ ($\approx 1.7$ секунд в сутки)

***Конец описания модели***

#### Синхронизация часов (невозможна)

Drift неизбежен, но можно ли устранить Skew сведя часы к одному показанию, не обязательно к "реальному" времени? Докажем, что это невозможно

Попытаемся синхронизировать два узла. Узнаем на узле время $t_1 = Now \left( \right)$, запросим время у другого узла и при получении ответа $t_3$ снова узнаем время $t_2 = Now \left( \right)$. Примерная задержка ответа $\delta \approx \frac{t_2 - t_1}{2}$. Значит, если сеть симметрична, на другом узле сейчас $t_3 + \delta$

Пусть время доставки сообщений $delay \left( m \right) \in \left[ \Delta - u, \Delta \right]$, где $u$ - uncertainty (неопределённость), и дрейфа нет. Синхронизировать часы означает выбрать для каждого узла некоторую поправку $O_k$ к текущему показанию его часов $SC_i \left( t \right) = C_i \left( t \right) + O_i$. Предположим, есть произвольный алгоритм, который после запуска за некоторое время даст $\left| SC_i \left( t \right) - SC_j \left( t \right) \right| \le \varepsilon$. Определим нижнюю оценку $\varepsilon$, т.е. насколько точно можно синхронизировать часы

Пусть мы управляем миром, в том числе работой сети (задержками) и начальным отклонением часов, иными словами, можем вообразить любые возможные исполнения (эта техника полезна при доказательстве алгоритмов). Построим два различных исполнения, в которых поправки вычисляются независимо и в общем случае должны различаться, но таких, что алгоритм не сможет уловить различий и выберет в обоих случаях одинаковые поправки

$t_{i \to j}$ - время доставки сообщения от $i$ к $j$. Пусть $t_{1 \to 2} = \Delta$, $t_{2 \to 1} = \Delta - u$. На такой конфигурации запускаем алгоритм и вычисляем $\varepsilon$. Затем делаем **shift** - оставляем события на первом узле на тех же местах, но переворачиваем сеть ($t_{1 \to 2} = \Delta - u$, $t_{2 \to 1} = \Delta$), и также переводим часы второго узла на $+u$, чтобы ответы остались такими же. Оба узла не видят разницы, значит в обоих случаях алгоритм выберет одинаковые поправки $O_k$, но для второго узла 

```math
C^{'}_2 \left( t \right) = C_2 \left( t \right) + u \Rightarrow SC^{'}_2 \left( t \right) = SC_2 \left( t \right) + u \Rightarrow SC^{'}_2 \left( t \right) - SC_2 \left( t \right) = u
```

И поскольку разница между двумя часами может быть от $-\varepsilon$ до $\varepsilon$, то

```math
SC_2 \left( t \right) \in \left[ SC_1 \left( t \right) - \varepsilon , SC_1 \left( t \right) + \varepsilon \right], SC^{'}_2 \left( t \right) \in \left[ SC_1 \left( t \right) - \varepsilon , SC_1 \left( t \right) + \varepsilon \right] \Rightarrow 2\varepsilon \ge u \Rightarrow \varepsilon \ge \frac{u}{2}
```

В случае n узлов

```math
\varepsilon \ge \left( 1 - \frac{1}{n} \right) u
```

Мы не можем оценить асимметрию сети, только измерить время roundtrip-а - путишествия сообщения туда-обратно. Стоит отказаться от синхронизации времени, поскольку время это разделяемое между узлами состояние, которое не является когерентным. Именно поэтому safety не должно зависеть (и не зависит) от времени, лишь liveness

Всё становится лучше, если отказаться от асимметрии, например, синхронизировать одни часы по другим, но не обратно

#### Почему GPS синхронизирует часы

Из соображений геометрии нужны три спутника для точного определения положения в пространстве. Достаточно пересечь сферы расстояний и взять точку на поверхности Земли. Это выливается в систему трёх неизвестных $\left| X - X_i \right| = d_i$. Однако расстояние до спутников измеряется при помощи локальных часов, которые имеют погрешность $\delta$ относительно времени GPS, так что система на самом деле выглядит так $\left| X - X_i \right| = \upsilon * \left( \Delta t_i + \delta \right)$, что складывается в четыре неизвестных и четыре уравнения - *навигационные уравнения GPS*. Поэтому синхронизация часов является побочным результатом. Чтобы это работало, часы на спутниках имеют огромную точность (у них очень маленький drift, избыточность кристаллов, и их постоянно синхронизируют)

#### TrueTime

**Google.TrueTime** - локальный сервис для синхронизации часов. Вызов $TT.Now \left( \right)$, используя локально сохранённое состояние на узле, возвращает диапазон $\left[ e \left( arliest \right) , l \left( atest \right) \right]$, в пределах которого находится истинное время. Гарантируется, что $\left[ t_0, t_1 \right] \cup \left[ e, l \right] \ne \emptyset$ и $l - e \le 6ms$, где $t_0$ - истинное время отправки запроса и $t_1$ - истинное время получения ответа (например, запроса внутри `Spanner`). Для этого каждые $30$ секунд демон сервиса TT на узле синхронизирует локальное состояние (интервал $\left[ e_0, l_0 \right]$), неизменное до следующей синхронизации, с одним из *тайм мастеров* кластера (в пределах одного датацентра), а ppm устанавливается в $200$, что заведомо больше, чем в часах узла. При запросе $TT.Now \left( \right)$ сервис берёт копию локального состояния и сдвигает границы, имитируя дрейф, используя монотонные часы, нижнюю c $ppm = -200$, а верхнюю с $ppm = 200$. Так интервал с настоящим дрейфом заведомо попадает в вычисленный

Тайм мастеров два вида, либо узел с *GPS антеной* (для синхронизации своих часов по GPS), либо *Armagedon Master* с атомными часами. Они независимы и имеют разные сценарии отказа

TrueTime используется для замены долгого межконтинентального общения ($\sim10-100ms$) ожиданием не дольше $6ms$ (в настоящее время сильно меньше). Этот сервис был построен для использования в `Google Cloud Spanner`

## Seminar 1. Среда исполнения распределённой системы

**Геораспределённая система** - система, узлы которой расположены на большом расстоянии друг от друга, в масштабе земного шара

**Leap second (добавочная секунда)** - поправка ко времени из-за неравномерного вращения Земли. В мире существует несколько временных осей, которые возникли из-за leap second
- **TAI** - время без добавочных секунд
- **GPS** - время в одноимённой системе. Учитывает добавочные секунды до момента запуска
- **UTC** - "настоящее" время. Включает все добавочные секунды

Unix time не монотонно, как из-за наличия leap seconds, так и в результате синхронизация с GPS (протокол *NTP*). Поэтому возможно, что в следующую секунду будет тот же timestamp, либо даже меньший. Нельзя в распределённых системах полагаться на монотонность течения "общего" времени (по временным осям). Поэтому в компьютерах существует *двое часов*
- **wall clock (настенные, календарные)**, `std::system_clock` - имеют единую точку отсчёта на разных узлах, но не монотонны. Могут быть использованы для сравнения времени на разных узлах
- **monotonic clock**, `std::steady_clock` - не имеют единой точки отсчёта, но монотонны (например, монотонность устанавливается от запуска системы). Позволяют измерять диапазоны локально

Независимо от вида часов, они подвержены дрифту. Их различие в наличии/отсутствии корректировки времени

Узлы (сервера) собираются в *стойки (rack)* под объединением *коммутатора (top-of-rack/ToR switch)*, стойки собираются в *кластера (cluster)* под объединением *кластерного коммутатора (cluster switch)*, кластера собираются в *датацентры*, датацентры собираются в геораспределённую сеть. В правильно организованной инфраструктуре отсутствуют **single point of failure (SPF, единые точки отказов)** - точки, отказ в которых приводит к падению всей системы. Для этого необходимо размещать части системы (например, реплики) в разных доменах отказа. **Failure domain (домен отказа)** - часть системы, выходящая из строя из-за одного локального отказа. Диск $\to$ узел, коммутатор $\to$ стойка, коммутатор $\to$ кластер. Необходимо применять *rack awareness* - размещать реплики в разных стойках. Также следует стремиться уменьшать количество самих точек отказа, напрмер, через *избыточность* (запасные коммутаторы, несколько путей в сети между двумя узлами, raid-массивы и т.д.). Вариант уменьшения рисков отказа - резервирование коммутаторов от разных производителей (разные баги и условия выхода из строя). Но в месте с ростом надёжности увеличивается расстояние между узлами и издержки, поэтому растёт latency, так что важно находить балланс. Пример: фабрики Google или Facebook

**Недоутилизация** - ситуация простаивания избыточных мощностей/ресурсов, имеющихся с целью пережить пик нагрузки и для отказоустойчивости. Возникает также, когда пользователи по географическому признаку распределяются по частям системы, которые становятся активными лишь в определённое время. Именно поэтому вместо большого количества маленьких кластеров под отдельные сервисы стали строить один большой кластер на все сервисы сразу. В нём должна быть избыточность маршрутов (для предотвращения потери связности), высокая пропускная способность любого разреза, а также он должен легко масштабироваться без необходимости использовать специальное оборудование (должно быть достаточно того, что есть на рынке)

**Vendor lock** - зависимость от производителя, когда определённым товаром или товаром с конкретными свойствами торгует единственный производитель. Также возникает при экстримальном вертикальном масштабировании (процессор с самым большим числом ядер, самый вместительный диск и т.д.). Уменьшает надёжность системы

#### Почему между датацентрами на разных концах мира есть задержки

Идеал - скорость света. Материал оптоволокна неидеален, преломления, затухания сигнала, точки сварки, коррекция ошибок, разрыв кратчайших путей, соображения надёжности (не прямой путь), экономические соображения (провода к промежуточной точке в стороне, постройка датацентра и аренда кабеля вместо своего кабеля), географические особенности (реки, населённые пункты, существующие ж/д пути)

TCP является распределённой системой, и эта абстракция соединения (потока байт) существует лишь на уровне ОС двух участников (TCP стек находится в ядре, и ОС управляет соединениями, не на уровне сети/проводов/коммутаторов/маршрутизаторов, IP работает с Datagrams), т.е. TCP не имеет физического представления. Проблема TCP в том, что абстракция прямого провода (машина-машина) не соответствует физической действительности (в сети много пар машин, которые пользуются проводами сообща), поэтому нельзя писать сколько захочешь: перегрузка сервера, перегрузка сети, о которых не знают TCP концы (*Flow control*, *Congestion control*). Например, для отправки пакетов существует окно подтверждений, которые ещё не получены, и это окно при получении таймаута уменьшается в $2$ раза. Также TCP подвержен проблеме синхронизации часов: при гибели процесса ОС закроет соединение и пошлёт сигнал fin; если на другом конце машина перегрузится, она ответит, что не знает нас (соединение разорвано); если машина упадёт, мы будем сперва успешно писать в буфер, затем при его заполнении долго ждать отправки с ретрансмитами до таймаута. Так нельзя понять, что происходит в остальном мире прямо сейчас

TCP медленный, т.е. из-за flow и congestion control он начинает с маленьких скоростей прощупывать сеть и разгоняется

В действительности существует множество десятков версий протокола TCP

Современные распределённые системы начинают работать в облаках, поэтому для высокой производительности должны учитывать виртуализацию, контейнеры, планировщики кластеров и разделение ресурсов, и т.п.

## Lecture 2. Линеаризуемость. Репликация регистра, алгоритм ABD

Fault-Tolerant (отказоустойчивость) - свойство системы переживать отказ (нарушение нормального функционирования) любого из узлов. Решается некоторой степенью избыточности (Redundancy). К примеру даже отказ диска на одном сервере предотвращают использованием технологии RAID

Модель в общем: асинхронная модель, неизвестны скорость и порядок доставки сообщений, неизвестна скорость работы узлов, неизвестна скорость дрифта часов, из отказов лишь рестарты и смерть узлов (нет повреждений отдельных битов оперативной памяти космическими лучами, приводящих к каскадным эффектам), есть коррекция памяти, и нет византийских отказов

Будем проектировать KV Storage
- Set(key, value)
- Get(key)
- (диапазоны, транзакции и пр. в дальнейшем)
Почему этот класс распр. систем? Распр. база данных не получалась, и из неё выкинули фичи (транзакции, запросы, таблицы), а оставшуюся часть (key -> value) удалось сделать распределённой и хорошо. И уже поверх отказоустойчивого и распределённого слоя KV реализовали привычный интерфейс базы данных, т.н. SQL over KV

KV должен быть масштабируемым и отказоустойчивым, поэтому в нём много слоёв
- 1 уровень - Local Storage: построить в пределах одного узла эффективную систему с произвольным доступом (API) поверх диска с последовательным (Прим: LevelDB, RocksDB). Полагаем, что данные помещаются на один узел, диск используем на случай рестартов (Durability), а отказов не существует (большие данные и отказы решаем на уровнях выше)
- 2 уровень - Replication: организуем отказоустойчивость на случай отказов (смерти диска/узла). Реплицируем данные одного узла на 3-5 репликах (replica set). Реплика, потому что одинаковые. Если необходимо реплицировать неизменяемые данные, то можно применить erasure codes и сократить количество реплик в два раза без потери надёжности
- 3 уровень - Distribution: данные более не помещаются на одной машине, необходимо распределить их по кластеру (шардировать). Имеем много узлов и большой диапазон ключей (Key space) |-||-||-||-|, где |-| назовём range (или регион) [b, d], где b и d ключи. Ключи в range упорядочены. Каждый range реплицируется независимо на некотором replica set. Replica set разных range могут пересекаться, но в целом произвольны. Теперь каждый range будто самостоятельный KV Storage
- 4 уровень (последний для целей изучения) - Transaction. Через них реализуются транзакции в SQL (для распр. баз данных). На этом уровне заканчивается KV распр. система
- 5 уровень (не входит в KV Storage) - распределённое выполнение запросов и табличная модель SQL поверх них

Решаем задачу репликации одной ячейки памяти - регистра (задача моделирования разделяемой памяти в распр. системе). После реализации local storage решение можно будет расширить на весь диск
Register
- Write(v)
- Read()
Поскольку процессор есть распр. система, обобщим задачу синхронизации пямяти в нём. Здесь всё сложнее из-за отказов и ограничений (скорости) сети: на разных узлах в разные моменты времени значения ячейки будут отличаться, и система будет пытаться это скрыть от пользователя. Значит мы хотим получить от системы набор гарантий, например видимость своей же записи или видимость чужой записи по причинности (по сообщению, happens-before)

Конкурентная история - глобальная история конкурентных действий с регистром (чтений/записей) во времени, в которой операции либо состоят в отношении до/после (упорядочены во времени, Real-time ordered) и на схеме одна заканчивается раньше начала другой, либо не состоят, на схеме пересекаются, и можно считать, что они выполняются в произвольном порядке, который мы сами вольны выбрать. Помимо начала и конца на схеме отображается результат операции. Возможные конкурентные истории порождаются конкретной реализацией регистра с разными гарантиями в процессе работы с регистром
Последовательная история - история последовательных действий с регистром, которые не пересекаются во времени (будто все действия мгновенно выполняются одним пользователем в одном потоке). Прим. w(1) w(2) r->2 w(3) r->3. Сама по себе последовательная история не может быть правильной или нет, напр. в случае w(42) r-41
Последовательность действий с регистром каждого отдельного клиента является последовательной историей, которая обязана согласовываться с конкурентной историей
Спецификация (Spec) регистра - набор всевозможных допустимых (правильных) последовательных историй (или наблюдаемых поведений). Спецификация описывает, как может вести себя регистр (какие последовательности записей/чтений возможны), если к регистру нет конкурентных обращений. Спецификацию задают при проектировании регистра, напр. Atomic или Regular
Consistency Model (модель согласованности) - отвечает на вопрос: какие конкурентные истории может порождать реализация с заданной спецификацией
Объединяя всё вместе, спецификация говорит, как ведёт себя регистр в идеальной среде (один пользователь, синхронные операции, нет сбоев), а модель согласованности говорит, как регистр с такой спецификацией будет выглядеть в реальной среде, с конкурентным доступом и сбоями. Т.е. спецификация и модель независимы, но обе влияют на поведение

Хотим от регистра Linearizability (линеаризуемости, External Consistency - намёк на внешнюю коммуникацию), что является более общей моделью, чем Sequential, т.е. даёт больше гарантий
Линеаризуемость - для любой конкурентной истории, порождаемой реализацией некоторого регистра, существует допустимая (по спецификации) последовательная история, называемая Линеаризацией, построенная из тех же операций с теми же результатами, такая, что для любой пары операций o1 и o2, если в конкурентной истории операция o1 завершилась в физическом времени (абсолютном) до начала операции o2 (Real-time ordering, отсутствует в процессоре), то в последовательной истории операция o1 следует до операции o2 (требований к пересекающимся во времени операциям нет)
Линеаризация по сути единый для всех клиентов логический порядок операций, соответствующий спецификации, которым клиенты могут объяснить изменения в истории, как если бы система не была конкурентной, а операции выполнялись мгновенно. Так каждый клиент считывая регистр должен получить некоторую историю, которая является частью линеаризации. Линеаризация едина для всех клиентов, поскольку она строится по истории во времени, а время для всех одинаково. В случае возможности линеаризации клиенты обязаны видеть одну и ту же последовательность изменений, и наоборот, если истории с точки зрения клиентов противоречат друг другу, линеаризации невозможна. То есть, линеаризация означает, что результаты чтений разных клиентов, выраженные их личные последовательными историями, непротиворечивы и могут быть объединены в единую последовательную историю. Одновременно может существовать несколько линеаризаций для истории, но нас это не тревожит, нас устраивает наличие хотя бы одной (любой)
Регистр линеаризуем (atomic register), если его реализация порождает только линеаризуемые истории. Для пользователя это означает, что он может не думать о системе как о распределённой, что она действует атомарно, операции случаются мгновенно одна за одной, и конкуренция не важна
Грубые объяснения линеаризуемости: 1. как будто внутри системы существует мьютекс на любое взаимодействие с ней 2. на отрезке действия в конкурентной истории найдётся точка, выбрав которую можно думать, что операция произошла в ней атомарно; эти точки будут отражать линеаризацию 3. отсутствуют циклы в графе порядков 4. то, как конкретный пользователь видит систему

Но как мы может оперировать понятием Real-time ordering, если доступа ко времени нет, а часы не идеальны и не синхронизируемы. Установить RT ordering конца-начала конкурентных действий ни система, ни клиенты не могут. Вместо времени клиенты думают о причинности (happens-before)(порядок локальных действий, реакции на внешние сообщения). hb => RT ordering (действие не может стать причиной события в прошлом). Система об hb не знает (он снаружи), но должна выставить операциям некоторый порядок (timestamps). Поскольку timestamps выдаются последовательно (это нужно обеспечить), то из их порядка => RT ordering. Итого, система не знает о hb, клиенты не знают о timestamps (в некоторых системах знают), но оба этих порядка согласованы через общее время (RT ordering), значит система учитывает hb
Теперь мы без времени знаем какие события следуют до каких
Линеаризуемость ничего не говорит о пересекающихся операциях, поскольку пользователь не удосужился установить между ними hb, потому как сам не ожидает порядка от этих операций

Atomic Register
- Write(v, t - timestamp)
- Read
- операции блокирующие
Asynchronous model
Crash/Restart

Какой размер у replica set (от этого некоторым образом зависит отказоустойчивость, или допустимое число отказов)? Интуитивно возьмём три реплики (затем алгоритм можно будет обобщить). Упрощения
- первое - конфигурация статична (не умеем заменять отказавшие узлы, добавлять новые)
- второе - клиенты знают количество и адреса машин, и общаются с ними напрямую. Реплики не общаются (устраним после построения алгоритма)
- третье - пишет только один конкретный клиент (после его смерти писателей нет) и строго последовательно, читателей произвольное число (устраним после построения алгоритма)
Алгоритм
Пишем на три реплики, ждём подтверждения с двух (одно не отказоустойчиво, трёх можем не дождаться). Каждая реплика хранит копию регистра, и значения в них не синхронны. Поскольку записи могут обгонять друг друга, чтобы реплика не перетёрла новое значение старым, писатель снабжает записи timestamp-ами (временные метки, счётчик операций). Реплика последовательно обрабатывает приходящие записи, при большем timestamp-е записывает значение, иначе отбрасывает (в MVCC системах (YDB) всё равно записывается), и безусловно посылает подтверждение. Blind write - безусловная запись без сравнения с текущим значением
При чтении аналогично, дожидаемся двух ответов и выбираем с большим timestamp-ом

При 3-х репликах необходимы два ответа, и допустим один отказ. В случае n реплик число отказов, f <= n/2, и необходимо n/2 + 1 подтверждений (эти числа не меняются при отказах). Множества подтверждений на запись и чтение должны пересекаться, т.е. иметь общие узлы по принципу Дирихле. Это обобщается в Quorum System: P - множество всех узлов, Q - система кворумов (подмножеств этих узлов) и принадлежит 2^P, и для любых множеств A и B из Q, A и B пересекаются. В случае регистра A и B это наборы реплик, отправившие подтверждения записи и чтения. Система кворумов Majorities - минимальные строгие большинства. Quorum означает минимальное количество голосов для принятия решения. Говорят операция чтения или записи собирает кворум (нужное число подтверждений). Если запись real-time ordered before чтения, ожидаем, что кворум чтения увидит узлы из кворума записи. Система блокируется, когда невозможно собрать любой кворум (нужно использовать таймауты). Т.о. Quorum System - это инструмент сокрытия отказов
Не стоит выбирать чётное число реплик, поскольку размер кворума вырастает на единицу, а отказоустойчивость не изменяется
Также есть гибкость выбора кворума. Необязательно стремиться к равным значениям на чтение и запись: на 5 репликах можно дожидаться 4 записей и 2 чтений, и чтения стали быстрее за счёт более медленных записей, также число отказов на чтение стало больше за счёт меньшего числа отказов на запись
Ни система, ни клиент не видят отказов. Но что делать, если число отказов превысило допустимый предел. Самое простое, перестать отвечать (кворум не собирается, клиент таймаутится)
Quorum System также позволяет избежать split brain: поскольку для кворумов A и B должны пересекаться, то выбрав некоторое множество узлов, оставшиеся не смогут собрать кворум. Так, либо обе части смогут собирать кворум лишь на чтение, либо меньшая часть станет недоступной (если же кворум записи меньше кворума чтения, возможна ситуация, когда в обе части можно лишь писать). Замечательно то, что после восстановления partition система может продолжать функционировать без внешней синхронизации по построению алгоритма: значения в отключённой части будут отбрасываться (по timestamp-у), пока она не актуализируется. Также система кворумов поясняет, почему нельзя добавлять машины: на новых будут бОльшие кворумы, что хорошо, но на старых станут мЕньшие, которые могут не учесть актуальные данные

В такой системе линеаризуемость отсутствует. Пусть неоконченная запись попала на реплику 1, и клиент делает два чтения (или разные клиенты), сперва с реплик 1 и 2, затем с 2 и 3. Он увидит сперва новое, затем старое значения. Это не линеаризуемая история, и регистр не атомарен. Прим: Cassandra пользуется таким алгоритмом, поскольку решаемые ею задачи не требуют такой гарантии, при этом она на другом слое делает оптимизации за счёт упрощения здесь
Суть в том, что кворум собирается не мгновенно, это продолжающееся действие. По сути, клиент сам того не понимая наблюдает отдельные локальные изменения и видит незавершённую запись (он не пересёкся с кворумом, а захватил отдельный узел). Необходимо обеспечить "видимость" лишь собранных кворумов

Ситуацию чинит helping. Сделаем чтение двухфазным. Сперва выполняем обычное чтение, затем с той же временной меткой выполняем запись, собирая кворум (оптимизация: одинаковые timestamp-ы -> кворум есть, запись не нужна). Теперь по окончанию нашего чтения, последующие в real-time order чтения гарантированно увидят по крайне мере то же, что и мы. Так мы получаем линеаризуемость за счёт усложнения/замедления чтения. Исходный сценарий всё ещё возможен, однако теперь первое чтение гарантированно пересекается со вторым во времени, значит их можно переупорядочить

Итого, если клиент обеспечил hb, значит операции не пересекаются во времени, а значит они пересекаются по состоявшимся кворумам. Если же hb нет, операции могут пересекаться, и порядок во времени может быть любым (при линеаризации выберем тот, что нам удобнее)

Док-во линеаризуемости построенного алгоритма. Между собой записи упорядочены единственным писателем, чтения упорядочены по timestamp-ам (т.е. здесь невозможно прочитать или записать более старое значение). Поставим чтения после прочитанных ими записей, но не раньше других чтений, которые real-time ordered before них. Если операции пересекаются во времени, мы от них ничего не требуем, иначе всё хорошо по кворумам. Доказательство по монотонности timestamp-ов

Для нескольких писателей нужно уметь распределённо выбирать единый монотонный timestamp. Путь ts = Now(). В реальности клиент посылает запись, она попадает на узел координатор (один из), который вызывает Now(), собирает кворумы и подтверждает операцию клиенту (т.е. алгоритм реализован на стороне сервера, не в клиенте). Но что делать с тем, что у разных координаторов несинхронизированы часы (нужна монотонность)
Делаем запись двухфазной. Сначала через фазу чтения получаем timestamp и используем его увеличенное на 1 значение для фазы записи. Теперь операции чтения и записи равны по стоимости. Снова получили свойство, что кворумы на чтение и запись РАЗНЫХ операций записи пересекаются в процессе их выполнения. Но теперь возможна новая проблема - одинаковые timestamp-ы
Чтобы не допустить одинаковые timestamp-ы делаем их лексикографическими: парой (ts, id), где id - уникальный идентификатор реплики или клиента (в зависимости от алгоритма генерации timestamp-ов), задающийся при установке конфигурации. Нас не волнует неравнозначность реплик, поскольку без hb пользователь и так ничего не ожидает
(см. Hybrid Logical Clock (YDB) как аналог, где нет фазы чтения)

В Google используется TrueTime.Now(), который заменяет дорогие коммуникации узлов (лишняя фаза чтения с целью узнать прошлое) на ожидание и упорядочение по атомным часам. Это называется Commit Wait (Spanner): для транзакции берётся метка ts = TT.Now().latest, после чего ждём, покуда TT.Now().earliest >= ts, и тогда посылаем подтверждение. Теперь никакие транзакции не выберут более ранний timestamp, а значит произойдут позже

Как поддержать рестарты? Сперва реплика надёжно пишет регистр на диск, после отправляет подтверждение. В случае рестарта реплика восстанавливает регистр и оказывается в состоянии как после partition (необходимо догнать актуальные timestamp-ы). По идее таким же образом, но крайне неэффективно, можно заменять отказавшие узлы: считай что заменённый узел был в partition со старта работы регистра

Как оценить эффективность алгоритма? Нужна модель стоимостей. Два основных расхода времени (влияющие на latency): RTT (RoundTrip Time) - время между отправкой сообщения и получением ответа, Disk - время записи на диск вместе с flush (fsync - отправить данные из страничного кэша на диск). В зависимости от удалённости узлов и вида диска может превалировать одно из двух. Вся операция внутри системы (обе фазы) называется Quorum flush - инициировать кворум, каждой репликой обработать запрос со сбросом диска, собрать ack-и

## Seminar 2. Реализация регистра в коде

Конфигурация системы постоянно меняется (отказы, обслуживание, расширение, проблемы сети), поэтому общаться с ней через конкретные адреса реплик неудобно (с некоторыми исключениями, см. Cassandra). Вместо этого клиент посылает запрос на какой-то узел, который выполняет операцию
В связи с этим у узлов две роли
- Coordinator - активная роль (алгоритмическая), методы (API) Set/Get: при запросе клиента инициирует работу с регистром как единым объектом (выбирает ts, собирает кворумы и т.д.)
- Replica - пасивная роль (структурная), методы (API) LocalRead/LocalWrite: при запросе координатора работает со своей копией регистра (сравнивает ts, обновляет значение, отвечает координатору и т.д.)
Для удобства координатор отправляет команду сам себе (loopback интерфейс). В коде правильно будет использовать для интерфейса (базовых класса - декомпозиция)
Удобно сделать роли отдельными серверами/сервисами и заменить Message Passing на Client-Server. В коде запросы к серверам осуществляются не через Callback-и, а через RPC - координатор общается с репликой будто она объект и вызывать его методы (именно так работают библиотечные клиенты на С++ различных распр. систем, client = KVStore(); client.Set(k, v)). Цель RPC - убрать из кода особенности сетевого взаимодействия, а также связать запрос и ответ

Клиент в своём коде выполняет RPC, на координатор приходит запрос, под который порождается файбер/корутина, который асинхронно дожидается сбора кворумов, первого и второго

Поскольку сеть ненадёжна (теряет сообщения), нужны Retry, которые нужно уметь останавливать, так что нужны cancellation, отправляемые по сбору кворума, по окончанию scope (RAII токен), по смерти корутины/файбера или по ручному завершению (stop token). Главное использовать таймауты (или иметь аналогичные механизмы отмены) в асинхронных системных вызовах, чтобы помимо ресурсов программы можно было освободить ресурсы ОС
Именно из-за retry-ев реплики посылают ack даже на запоздавшие записи, поскольку такое может случиться на большинстве узлов, и в противном случае таска бесконечно крутилась бы без возможности собрать кворум
