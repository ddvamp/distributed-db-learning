## Seminar 5. RPC-фреймворк

Мотивация RPC
Вспомним реализацию KV Store из 2 лекции. Клиент посылает запрос, который попадает на некоторый узел, и тот берёт роль Координатор. Координатор активен, инициирует коммуникацию и собирает два кворума, на чтение и запись. Узлы, которые стали участниками кворума, берут роль Реплика. Реплики пассивны, не инициируют коммуникацию, лишь выполняют указы Координатора. У этих ролей разное поведение, разные реакции на разные сообщения, поэтому в коде их удобно разделить на два интерфейса со своими API. Координатор является сервером для внешних пользователей и клиентом для Реплик. Как клиент Координатор посылает запросы и ждёт ответы, и здесь неудобно использовать модель асинхронных сообщений или коллбэков. Будем использовать RPC

Описание RPC

Верхний уровень
RPC (Remote Procedure Call) позволяет скрыть детали сети и рассуждать в терминах объектов. С RPC сетевой запрос начинает выглядеть как локальный вызов функции, который возвращает результат исполнения на удалённой машине. Для этого нужны два представления одного объекта. Удалённый объект-исполнитель называется Service, локальный объект-представление называется Stub, оба реализуют один интерфейс, наследуя общий базовый класс. Клиент в коде вызывает метод Stub-а, и после на сервере RPC-фреймворк вызывает этот же метод у Service-а с теми же аргументами, что и клиент. Для этого аргументы сериализуются и посылаются с запросом. Stub/Service есть верхний уровень всей схемы, который оперирует понятиями метод, аргументы и типы. Заметим, что как на Stub-е, так и на Service-е, мы хотим осуществлять вызовы конкурентно, однако на этом уровне понятия конкурентности нет. Stub/Service потокобезопасны, синхронизация осуществляется уровнем ниже

Уровень транспорта
Взаимодействие объектов осуществляется через отправку сообщений туда-обратно по сети. Эту задачу решает уровень Transport (доставка), являющийся обязательной частью любого RPC-фреймворка. Он видит только сообщения как нетипизированные строки байт, не понимая их содержания, и не видит семантики запрос-ответ. Транспорт (интерфейс) предоставляет два механизма (метода): Connect, чтобы клиент установил соединение по адресу и Serve, чтобы сервер слушал порт. Формат адреса/порта зависит от реализации, и это не обязательно числа. Connect возвращает интерфейс-сокет, через который можно асинхронно посылать сообщения, и регистрирует обработчик обратных сообщений. Serve устанавливает обработчик входящих сообщений и разрыва соединения, и получает интерфейс-сервер. Реализация Transport может использовать любой протокол. TCP, HTTP, свой протокол, например эмуляция TCP без обращений в сеть

Уровень канала
Между транспортом и внешним слоем существует промежуточный уровень, пара Channel - RPC Server. Для channel-а абстракцией транспорта является интерфейс-сокет, для RPC server-а - интерфейс-сервер. На этом слое выполняется синхронизация, т.е. у всех физических Stub/Service одного логического объекта под капотом одна и та же реализация канала. Также канал является обработчиком, регистрируемым в Serve. Для конкурентного выполнения многих действий внутри канала нужно использовать Strand, просто сериализуя все обращения к нему. Со стороны канала есть Future<Message> + Await (Message a.k.a. std::string), со стороны RPC сервера есть Concurrent Handlers многих клиентов (Fiber/Coroutine + Thread Pool). Также на стороне канала для сообщений возникает семантика request/response, т.е. канал понимает, к какому запросу относится ответ, храня в себе отображение из RequestId в структуру ActiveRequest. Т.е. у канала есть метод Call, который принимает Method - имя сервиса и имя метода, Message - сериализованные аргументы и опции вызова, а возвращает Future на сериализованный ответ. Этот уровень реализует модель канала из первой лекции

Примерная схема запроса
На стабе осуществляется вызов метода с набором аргументов, типы стираются, значения сериализуются в сообщение, стаб пишет в канал строку-метод и строку-сообщение, канал упаковывает их в сообщение и отдаёт интерфейс-сокету, транспорт доставляет сообщение на интерфейс-сервер, откуда его получает RPC-сервер, который знает на каком сервисе и что за метод нужно вызвать, передавая сообщение, а сервис десериализует аргументы и восстанавливает типы, после чего выполняет вызов. В обратную сторону также, стаб десериализует Message из Future и возвращает ответ

В действительности в такой архитектуре (де)сериализация осуществляется дважды: сериализация вызова в структуру с полями описания сервиса, метода, аргументов, и сериализация структуры-описания в сообщения - строку байт

Protobuf - протокол сериализации, который позволяет участвующим сторонам быть написаным на разных языках. Использует varint encoding - кодирует не типы, а значения, тратя на них столько байт, сколько они занимают. Альтернативой ему является zero-copy buffers, которые используются например в Cap'n Proto. Суть в том, чтобы класть в сеть ровно то, что содержится в байтах для сериализации (?trivially-copyable типы). Трейдоф - количество данных, посылаемых в сеть не уменьшить

Транспорт должен быть производительным, т.е. большое количество сообщений в обе стороны должны быть упакованы в малое количество TCP соединений. Также нужна кроссплатформенность языков. Этими свойствами обладает HTTP/2. HTTP/2 для TCP всё равно что fiber для thread, буквально. Файберы суть упаковка маленьких задач в потоки под тяжеловесным управлением ОС. Поверх логического TCP соединения есть много независимых конкурентных потоков данных из отдельных фреймов уровня HTTP/2. Протокол склеивает все фреймы в один поток байт, поэтому flow control должен быть обеспечен для каждого потока фреймов в отдельности

Очень удобно использовать HTTP/2 как транспорт в RPC, где отдельные вызовы будут упаковываться во фреймы

Как правильно реализовывать deadline/timeout на RPC вызов - добавить его к запросу и отправить на сервис, который этим будет заниматься

[↑ Содержание ↑](https://github.com/ddvamp/distributed-db-learning/tree/main/notes/dist-sys-mipt#содержание)\
[← Лекция 5](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/lectures/lecture-5.md)
[Лекция 6 →](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/lectures/lecture-6.md)
