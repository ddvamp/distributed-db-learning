## Lecture 8. Paxos Made Live

Рассмотрим, как взять Multi-Paxos и довести его до production-ready RSM, т.е. какие ещё задачи помимо репликации лога нужно решить, что можно ускорить или промасштабировать, а также, как консенсус может выглядеть в проде

#### Консенсус в проде. Lock Service. Lease

**Lock Service (сервис блокировок)** - сетевой сервис для обеспечения консенсуса, предоставляющий пользователям отказоустойчивую систему распределённых блокировок с API acquire/release (или lock/unlock). Он, вместо подключения в коде локальной библиотеки консенсуса, используется по модели *consensus as a service (CaaS)*. По сути это RSM, доступ к консенсусу которого выдаётся наружу. Интерфейс блокировок призван быть более интуитивным и простым, чем консенсус. Пример - `Chubby`, используемый в `BigTable` для хранения метаданных и TODO ещё чего-то

Сервисом одновременно пользуются разные клиенты, поэтому для адресации блокировки выстроены в иерархическую структуру - дерево. Клиент может владеть целой ветвью и выделять её подветви подсистемам. Для взятия блокировки используется путь до узла - $` Lock \left \lparen path \right \rparen `$. В основном сценарии блокировки Lock Service берут надолго, поэтому на случай "зависания" клиента (отказ, проблемы сети и т.д.) блокировка представляет собой **Lease = Lock + Timeout**. По истечению timeout-а система "забирает" блокировку. Для обновления таймаута через библиотеку сервиса устанавливается **Session** - логическое подключение, которое заключается в посылке системе Heartbeat-ов. Состояние сессии также реплицировано, поэтому она не разрывается при отказе участвующего в ней узла системы

Когда Lock Service-ом пользуется распределённая система, она, при "зависании" своего узла, заного запрашивает Lease на другом. Медленный узел не отличить от сбойного, и, возможно, несколько узлов в моменте будут иметь блокировку. Distributed lock by design не может гарантировать Mutual Exclusion. Поэтому Lock также снабжён **эпохой** (**Epoch**, аналог Ballot number), которую клиенты должны использовать

В действительности при помощи Lock Service выбирают лидера, который и использует эпоху. Альтернатива lock-ам - распределённые atomic-и, которые позволяют строить распределённые lock-free и wait-free алгоритмы. Пример: `Apache ZooKeeper`, написанный по мотивам `Chubby`

#### RSM в проде

В статье *Paxos Made Live - An Engineering Perspective* про опыт написания `Chubby` замечено, что между описанием алгоритма Paxos в несколько десятков строк и его промышленной реализацией в несколько тысяч строк есть зазор в десятки нерешённых задач. Рассмотрим часть из них, чтобы развернуть RSM

**Роли узлов.** Алгоритм определяет две роли
- **Proposer** - общается с клиентом и задаёт порядок операций
- **Acceptor** - обеспечивает согласованность этого порядка и управляет состоянием лога

но на практике появляется третья
- **Learner (Replica)** - отвечает за хранение состояния автомата и применение к нему готовых операций. Похожа на реплики Chunk Store из DFS ([семинар 4](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/seminars/seminar-4.md#данные-и-метаданные))

Общая схема взаимодействия. Клиент посылает комамнду Лидеру, одному из Proposer-ов. Лидер рассылает её Acceptor-ам, реплицируя в логе. После сбора кворума, и когда команду можно применить, лидер рассылает её Learner-ам и после отвечает клиенту. Так Acceptor-ам не нужно понимать, в каком состоянии ячейка и лог с точки зрения применения команд. За это отвечает один Лидер, а для Acceptor-ов лог всего лишь инструмент для проведения множества одновременных консенсусов

Не обязательно, чтобы каждый узел играл все три роли. Если их разделить, можно добиться лучших масштабирования, отказоустойчивости и оптимизации

TODO: Действительно ли Proposer посылает Learner-ам команду дополнительным сообщением?

**Число реплик.** Если хотим пережить $` f \lt \left \lceil \frac{n}{2} \right \rceil `$ отказов, необходимо взять $n = 2f + 1$ реплик. Если рассматривать оценки по ролям, то для Acceptor-ов необходимы $2f + 1$, а для Proposer-ов и Learner-ов по $f + 1$ реплик. Так получается, потому что только Acceptor-ы участвуют в кворумах, а для выбора лидера или хранения автомата достаточно одного живого узла

Если приемлимо разместить систему в одном ДЦ, то хватит $3-7$ реплик. При большем количестве лишь увеличится вероятность медленных машин

**Зависимость отказов.** Нельзя размещать реплики в одном Failure Domain, поэтому важно не просто выбрать число реплик, но и как их расставить. Чем выше уровень иерархии для размещения реплик, тем надёжнее, но тем больше задержки на коммуникацию (tradeoff)

В действительности можно выбирать число отказов для каждого Failure Domain отдельно. Обычно, чем крупнее система, тем до более высоких уровней подбирают числа

**Реконфигурации.** Наивное изменение состава реплик не работает. Пусть новая реплика добавляется через рассылку остальным. Очевидно, будет промежуток времени, когда часть узлов живёт в старой конфигурации. И если добавить два узла подряд, старый может начать собирать кворумы меньшего чем нужно размера. Проблема в том, что невозможно знать, когда все реплики обновятся, и выждать момент между добавлениями. Медленный и сбойный узлы неотличимы. Здесь время начинает взаимодействовать с safity, чего допускать нельзя. Выключить систему для переконфигурации также не годится

Естественное решение - внести реконфигурации в протокол команд. Реплика помнит текущую конфигурацию $` C_0 `$ и применяет её к слотам. Чтобы изменить конфигурацию на $` C_1 `$, нужно послать служебную команду $` Reconfig \left \lparen C_1 \right \rparen `$, игнорируемую RSM. Как только команда принята, начиная со следующего от её слота будет применяться $` C_1 `$

В таком решении параллельность недопустима из-за сценария наивного решения - недостаточный размер преждевременно инициированного кворума. Применим **$\Alpha$-method** - зафиксированная в слоте $k$ конфигурация начинает действовать лишь со слота $k + \alpha$, где $\alpha$ выбирается единожды и глобально. Тогда лог можно заполнять параллельно, пока не исчерпано $\alpha$-окно, т.е. количество одновременных операций не больше $\alpha$

Это решение не позволяет восстановиться после исчерпания числа отказов, поскольку нельзя собрать кворум ("смерть цивилизации Paxos"). Оно всё же ограничивает параллельность, даже когда нет реконфигураций. При его реализации имеется множество частных случаев. И такое решение не работает в Raft из-за откатов лога

**Недетерминированность.** Стоит помнить о запрете на использование случайных величин, времени, хэш-таблиц, об обратной совместимости реплик при обновлении кода/протоколов/версий библиотек/конфигурации, чтобы состояния автомата не расходились

**Exactly-Once.** Достижима лишь при усилиях и со стороны RSM, и со стороны клиента

TODO: Как именно?

**Batching.** Лидер, будучи одним узлом, тратит много усилий на репликацию небольшой команды. Уменьшим нагрузку на него. Поставим перед Proposer-ами $f + 1$ **Proxy** узел (ещё одна "инженерная" роль), которые получают команды от клиентов, в течение, например, $500ms$ собирают их в пачки и отправляют лидеру. Перед применением пачка распаковывается

TODO: В этом случае Proxy кэшируют лидера, а клиенты посылают запрос на произвольный Proxy? Нас не беспокоит ещё один RTT?

Новая роль введена, поскольку лидер выполняет много различных действий и пропускает через себя много сообщений. В теории существует модификация, чтобы репликацию (сбор фазы Accept) также выполняли другие узлы

**Read-only.** И модифицирующие операции, и операции чтения, которых гораздо больше, все проходят через протокол репликации для обеспечения линеаризуемости. Поэтому Paxos не различает команды, это умеет лишь автомат. Однако интуитивно хотелось бы выполнять чтения быстрее и локально, вне протокола, поэтому было бы полезно различать их

Наивно прочесть состояние с произвольной реплики нельзя, поскольку она может отставать - **Stale Read**. Читать с лидера тоже нельзя, поскольку реплика, считающая себя лидером, может находиться в меньшей части partition, и иметь устаревшие данные, не зная об этом

Можно на любой реплике собрать кворум, аналогичный Prepare, чтобы пересекался с любым кворумом Accept, и запросить индекс старшего непустого слота. Затем подождать, покуда локальная копия лога будет зафиксирована вплоть до максимально полученного индекса, тем самым обеспечив линеаризацию, и ответить клиенту. Более того, чтения также можно собирать в пачки

TODO: Итого простая и более частая операция требует кворум большего размера, чем модификации, плюс ожидание. В чём смысл? Не должно ли это быть медленнее?

Альтернатива. Пусть лидер вместо просто Heartbeat-ов периодически просит реплики в течении некоторого времени слушать только его, собирая подтверждения. Тогда он будет уверен в своём статусе, значит иметь актуальный лог. Из-за использования часов нужно аккуратно корректировать выбранные интервалы обещания на лидере/репликах и подбирать время отправки очередного запроса. Также неясно, как это должно работать в самом начале, когда ещё ни одного раунда подтверждений не было. Если не выжидать достаточную паузу после смерти узла, заложенную в запросах, можно потерять линеаризуемость

**Переполнение лога.** Лог не должен иметь неограниченный размер. Он может попросту переполнит диск, либо новая или вышедшая из partition реплика будет свою копию лога очень долго восстанавливать. Зафиксированный префикс лога можно сохранить в виде Snapshot-а RSM с номером последнего слота и отбросить. И пусть снимок помещается в память

TODO: Что, если нет?

Простой способ сделать снимок - использовать **Copy-on-Write (персистентность)** в ОС. Syscall $` fork \left \lparen \right \rparen `$ копирует поток с таблицой страниц, указывающей на те же физические, в новый процесс. Если один из процессов хочет писать в общую страницу, он копирует её себе. **Fuzzy Snapshots** - реплика выполняет $` fork \left \lparen \right \rparen `$ и продолжает работать, чуть медленнее из-за CoW, а новый процесс read-only сохраняет состояние RSM на диск, после чего префикс можно сбросить

Чтобы уметь отбрасывать начало лога, он хранится в списке файлов - **сегментов**. Отбрасываются целиком снятые сегменты. Вставка в лог есть вставка в последний сегмент, а при его исчерпании добавляется новый. Чтобы сократить число записей на диск, все сегменты имеют фиксированный размер, например, $64MB$, а заполненность последнего сегмента отслеживается вручную. Тогда для сброса данных на диск вместо $` fsync \left \lparen \right \rparen `$ достаточно использовать $` fdatasync \left \lparen \right \rparen `$ со сбросом только критических метаданных, которые редко меняются. Так в большинстве случаев происходит одна запись/позиционирование

#### Ускорение RSM

Мы задали отказоустойчивость и не меняем её, но даже так, чтобы увеличить производительность RSM, нужно добавлять новые реплики. Проблема в том, что RSM в этом случае становится медленнее, поскольку размеры кворумов растут, конфигурация усложняется, а шансы столкнуться с медленными узлами и проблемами с сетью возрастают. Нужно оптимизировать кворумы. Paxos строится на пересечении кворумов *разных* фаз (Prepare + Accept), значит их размеры могут отличаться

Две техники ускорения кворумов
- **Striping**
- **Grid Quorums**

**Striping.** Фаза Prepare (выбор лидера) происходит значительно реже фазы Accept (репликация команды), поэтому эффективнее вторую делать меньше первой. Зафиксируем размер второго кворума. Тогда, чтобы при неизменной отказоустойчивости сохранить safity, нужно каждый раз при добавлении новой реплики увеличивать первый кворум. Например, можно конфигурацию 5/3/3 превратить в 10/8/3. Однако быстрее не стало

Воспользуемся идеей **RAID 0 - Striping ("чередование")** и будем отправлять сообщения не всем Acceptor-ам с ожиданием трёх быстрых ответов, а ровно трём, чередуя тройки. Нагрузка на реплики уменьшится, и пропускная способность вырастет в разы ценой увеличения задержек отдельных команд

TODO: Как понять и что делать, если в тройке отказал узел?

**Grid Quorums.** Вспомним, что *суть кворумов* не послать пересекающиеся наборы запросов, а получить *пересекающиеся наборы ответов*. Можно уменьшить фазу Prepare, если собирать кворумы не произвольно, а структурированно. Выстроим реплики в прямоугольник высотой размера кворума Accept. Тогда, если посылать запросы всем репликам, достаточно, чтобы в первой фазе собралась строка ответов, а во второй - столбец (в реализации нужно фьючи в линиях объединить в $All$, а разные линии собирать под $FirstOf$). Любая строка с любым столбцом гарантированно пересекаются в некоторой реплике. Число отказов должно быть меньше числа строк, иначе возможно, что ни одну не получится собрать, или напротив, принять медленный узел за отказавший и, не собирая строку целиком, не пересечься кворумами

Заметим, что если взять не столбец, а по одной реплице в каждой строке, то, очевидно, каждая из строк будет пересекаться со взятым множеством. Тогда по Striping можно посылать Accept запросы на произвольные тройки, образующие линию в проекции

При структурировании нужно помнить о разных Failure Domain. Допустим, все столбцы реплик распределены по разным Az. Тогда при выходе из строя одной Az будет невозможно собрать кворум Prepare. Чтобы переживать $F = 1$ отказ по всем Az при $Z$ зонах по $3$ реплики в них, можно собирать кворумы прямоугольниками, первый размером $Z - F$ зон на $2$ реплики, второй $F + 1$ зон на $2$ реплики

Заметим, что суть прямоугольников в том, чтобы у них нашлась общая действующая зона в которой найдётся общая рабочая реплика. Тогда достаточно собрать для первого кворума $Z - F$ любых столбцов по $2$ ответа и для второго $F + 1$ любой столбец по $2$ ответа, причём можно также применить Striping ко второй фазе. Здесь главное, чтобы обе фазы собирали одно и тоже, тогда всегда найдётся общий столбец, в котором найдётся общая реплика. Также можно собирать строки, но предполагаю, что в среднем это будет медленнее (строки длинные и их мало, в каждой крайне мало реплик, которые можно отбросить, следовательно, низкая степень свободы, столбцы же низкие и их много, а значит реплик, которые в них можно не собрать значительно больше, как и степень свободы)

TODO: Непонятно как в последнем варианте масштабировать систему при неизменном размере второго кворума

Пример использования, консенсус в `LogDevice` - система очередей `Facebook`, которую тот использует поверх трёх регионов по три датацентра каждый. Каждый replica set размещён в двух узлах каждого ДЦ каждого региона, всего $18$ реплик. Репликация осуществляется ровно на $4$ узла в $3$ ДЦ $2$ регионов с ротацией узлов, позволяя переживать $3$, $2$ и $1$ отказ соответственно

Лидер является неудобной точкой в геораспределённых системах. Для Multi-Paxos существуют вариации, которые ценой частичного порядка используют несколько Proposer-ов и убирают один RTT

Открытые вопросы
- как Alpha method работает с batching-ом
- как разные лидеры согласуют Striping множества
- как очищать лог, чтобы он не переполнял машину
- что делать при рестарте системы

[↑ Содержание ↑](https://github.com/ddvamp/distributed-db-learning/tree/main/notes/dist-sys-mipt#содержание)\
[← Лекция 7](https://github.com/ddvamp/distributed-db-learning/blob/main/notes/dist-sys-mipt/lectures/lecture-7.md)
